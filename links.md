---
layout: default
title: Links
permalink: /links
---

# Art/Style

[coolors.co/](https://coolors.co/) - A color palette generator

[paletton.com/](https://paletton.com/) - A color palette generator, using mathematical relationships

[gaugan.org/gaugan2/](http://gaugan.org/gaugan2/) - GauGAN online application that you can sketch and generate great images from very little information


# Math/Programming

[numcalc.com/](http://numcalc.com/) - Online numerical calculator, with arbitrary precision and symbolic computation

[sod.pixlab.io/](https://sod.pixlab.io/) - Embedded computer vision library


# Blogs/Websites

[pollylabs.org/](https://pollylabs.org/) - Polyhedral compilation curator

# Slides/Talks

[Polyhedral compilation, great for the diagrams and tiling explanation](https://pliss2019.github.io/albert_cohen_slides.pdf) - polyhedral compilation diagrams and tiling

# Software

[cdn.openai.com/papers/dall-e-2.pdf](https://cdn.openai.com/papers/dall-e-2.pdf) - DALL-E 2, a hugely impressive leap forward in image synthesis. [here's an article I wrote about it](/2022/dalle2)

[openai.com/blog/webgpt](https://openai.com/blog/webgpt/) - Interesting research looking at GPT model appplied to web browsers, with citing sources
  * [www.infoq.com/news/2022/01/openai-webgpt/](https://www.infoq.com/news/2022/01/openai-webgpt/) - OpenAI's WebGPT, a GPT-2-like model for text generation.

[arxiv.org/abs/2203.15556](https://arxiv.org/abs/2203.15556) - Chinchilla, better and smaller than GPT-3. Also, this paper has a great introduction that explains broad ideas in ML/AI

[theoladune.github.io/AIVC-Seminar/](https://theoladune.github.io/AIVC-Seminar/) - AIVC, AI-powered image/video compression

[bellard.org/nncp](https://bellard.org/nncp/) - Neural network based text compression

[github.com/tensorflow/compression](https://github.com/tensorflow/compression) - Tensorflow compression models
  * [hific.github.io/](https://hific.github.io/) - AI-based image compression (wow!)

[video-diffusion.github.io/](https://video-diffusion.github.io/) - Generates decent quality videos from text conditioning

[github.com/hzwer/arXiv2020-RIFE](https://github.com/hzwer/arXiv2020-RIFE) - Video frame interpolation (really good, use it on all your videos!)

  * I use this ALL the time... literally use it on any video to smooth it up
  * I wrote some instructions on setting it up [here](https://gist.github.com/cadebrown/54052d919ae7153eab6c57aeab6f0a36)


[github.com/NVIDIA/FastPhotoStyle](https://github.com/NVIDIA/FastPhotoStyle) - Style transfer model for images

[nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/) - NLP word encoding method

[github.com/DeclanRussell/NvidiaAIDenoiser](https://github.com/DeclanRussell/NvidiaAIDenoiser) - Denoising model for images, useful for Blender rendering and restoring low quality videos

[en.wikipedia.org/wiki/Wikipedia:Database_download](https://en.wikipedia.org/wiki/Wikipedia:Database_download) - Wikipedia database dumps (I'm working on a personal project with this...)

# Datasets

[toflow.csail.mit.edu/](http://toflow.csail.mit.edu/) - Vimeo90k dataset of high quality videos

[www.eleuther.ai/projects/owt2/](https://www.eleuther.ai/projects/owt2/) - Large web text database

[en.wikipedia.org/wiki/Common_Crawl](https://en.wikipedia.org/wiki/Common_Crawl) - Common crawl of the entire web

[cs.stanford.edu/people/karpathy/deepvideo/](https://cs.stanford.edu/people/karpathy/deepvideo/) - Sports-1M dataset, scraped from YT


# Books

## Computer Science Books

[*The Art of Computer Programming*](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming)

: Possibly the best book on computer science ever written, deals primarily with algorithms and their implementations

[*Modern Computer Arithmetic*](https://books.google.com/books/about/Modern_Computer_Arithmetic.html?id=-8wuH5AwbwMC&source=kp_book_description)

: A useful book for implementing bignum arithmetic, goes into many, many algorithms and special cases. Basically all you need to write your own MPFR/libbf/GMP library

[*Advanced Programming in the Unix Environment*](https://en.wikipedia.org/wiki/Advanced_Programming_in_the_Unix_Environment)

: Heavily recommended for C programming, teaches the C standard library for UNIX OSes


## Math Books

[*The Elements*](https://en.wikipedia.org/wiki/Euclid%27s_Elements)

: Written by Euclid around 300BC, this book is a good introduction to the basics of mathematics starting with the basics of geometry

: In my opinion, this should be the first mathematics textbook for schools to use. It's ridiculous that most schools to teach students geometry without using Euclid's work. 

[*Prime Numbers and the Riemann Hypothesis*](https://books.google.com/books/about/Prime_Numbers_and_the_Riemann_Hypothesis.html?id=jyU7rgEACAAJ)

: Very useful book, for people of all backgrounds (not just mathematicians) that explains prime numbers, number theory, and the Riemann Hypothesis. Gives multiple formulations, diagrams, and explanations. My favorite book on my favorite problem in all of mathematics (so far)!


# Papers

[*On the Number of Primes Less Than a Given Magnitude*](https://en.wikipedia.org/wiki/On_the_Number_of_Primes_Less_Than_a_Given_Magnitude)

: Possibly the most influential (and yet still underrated) paper in all of mathematics, I highly recommend this paper. Check out [my blog post](/2020/08/05/diy-gamma-zeta) on the Gamma/Zeta function implementations

[*Design, Optimization, and Benchmarking of Dense Linear Algebra Algorithms on AMD GPUs*](https://www.icl.utk.edu/files/publications/2020/icl-utk-1405-2020.pdf)

: My paper, which discusses my work on porting and performance tuning the [MAGMA](https://icl.cs.utk.edu/magma/) library

[*Counterexample To Euler's Conjecture on Sums of Like Powers*](https://www.ams.org/journals/bull/1966-72-06/S0002-9904-1966-11654-3/S0002-9904-1966-11654-3.pdf)

: One of my favorite papers, although not particularly explanative. A computer-assisted dis-proof of one of Euler's conjectures

[*PolyJIT: Polyhedral Optimization Just in Time*](https://www.infosun.fim.uni-passau.de/publications/docs/SAGLijpp2018.pdf)

: Application of JIT techniques with polyhedral compilation

[*Diesel: DSL for Linear Algebra and Neural Net Computation on GPUs*](https://dl.acm.org/doi/pdf/10.1145/3211346.3211354)

: Example of a language geared at numerics-heavy compilation (focusing on neural networks)

[*Inverse Graphics GAN: Learning to Generate 3D Shapes from Unstructured 2D Data*](https://arxiv.org/pdf/2002.12674.pdf)


# People

[Gregory Croisdale](https://gregory.croisdale.us/)

: A frequent collaborator, we've worked together on [Avocat](https://github.com/utk-pairs/avocat), [CARVE](https://carve.chemicaldevelopment.us/), and many, many, more

[Stan Tomov](http://www.icl.utk.edu/~tomov/)

: My research advisor for ~2 years at ICL, who researches linear algebra and GPU computing

[Paul Zimmerman](https://en.wikipedia.org/wiki/Paul_Zimmermann_(mathematician))

: MPFR author, also the author of Modern Computer Arithmetic (a very very useful book). Also part of the team that factored [RSA 240 and 250](https://en.wikipedia.org/wiki/RSA_Factoring_Challenge)

