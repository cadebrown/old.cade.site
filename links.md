---
layout: default
title: Links
permalink: /links
---

# Useful Tools

[CLIP image retrieval: really good image search that has a better understanding of exact semantics than google](https://rom1504.github.io/clip-retrieval/?back=https%3A%2F%2Fknn5.laion.ai&index=laion5B&useMclip=false&query=polyhedral+art+with+geometric+fractal+patterns)

: I use this to find "stock images" (of course, check the [dataset terms](https://laion.ai/blog/laion-5b/)) which are good for artistic references

[pandoc: quickly convert documents between formats (.md, .rst, .pptx, $\LaTeX$, and more)](https://pandoc.org/try/)

: Since I've been using this tool, I just write every document up in markdown and use this when I need to convert it. 

# Art/Style

[coolors.co/](https://coolors.co/) - A color palette generator

[paletton.com/](https://paletton.com/) - A color palette generator, using mathematical relationships

[gaugan.org/gaugan2/](http://gaugan.org/gaugan2/) - GauGAN online application that you can sketch and generate great images from very little information


# Math/Programming

[numcalc.com/](http://numcalc.com/) - Online numerical calculator, with arbitrary precision and symbolic computation

[sod.pixlab.io/](https://sod.pixlab.io/) - Embedded computer vision library


# Blogs/Websites

[pollylabs.org/](https://pollylabs.org/) - Polyhedral compilation curator

# Slides/Talks

[Polyhedral compilation, great for the diagrams and tiling explanation](https://pliss2019.github.io/albert_cohen_slides.pdf) - polyhedral compilation diagrams and tiling

# Code/Software


[Stable Diffusion, open-source AI image generator](https://stability.ai/blog/stable-diffusion-announcement)

: WOW! Amazing results and freely available code. I'm using this for my personal projects I have in the works

: Best code is a non-official fork: [lstein/stable-diffusion](https://github.com/lstein/stable-diffusion) (has extra features, and runs on M1 mac). Official code is [CompVis/stable-diffusion](https://github.com/CompVis/stable-diffusion)

: Visual explanation of [diffusion and implementation](https://huggingface.co/blog/annotated-diffusion)

: Also, check out [stable diffusion video generation](https://github.com/nateraw/stable-diffusion-videos)

[DALL-E 2, by OpenAI](https://cdn.openai.com/papers/dall-e-2.pdf)

: DALL-E 2, a hugely impressive leap forward in image synthesis. [Here's an article I wrote about it](/2022/dalle2)

[GPT 3: NLP Model for Text Generation](https://en.wikipedia.org/wiki/GPT-3)

: State of the art in text generation, at 176 billion parameters

: Here's a [walkthrough of GPT architecture](https://dugas.ch/artificial_curiosity/GPT_architecture.html). Read this!


[WebGPT, by OpenAI](https://openai.com/blog/webgpt/)

: [Interesting article about WebGPT](https://www.infoq.com/news/2022/01/openai-webgpt/), a model meant to surf the web to answer questions

[Training Compute-Optimal Large Language Models (Chinchilla), by DeepMind/Google](https://arxiv.org/abs/2203.15556)

: Chinchilla, better and smaller than GPT-3. Also, this paper has a great introduction that explains broad ideas in ML/AI. Notable for also considering compute efficiency (LLMs are getting expensive, so this is becoming more important)

[AIVC, AI-powered image/video compression](https://theoladune.github.io/AIVC-Seminar/)

[NNCP: Lossless Data Compression with Neural Networks](https://bellard.org/nncp/)

: This guy is a legend... Has some of the best text compression, built with his own library

[Tensorflow compression models](https://github.com/tensorflow/compression) - Tensorflow compression models
  
: [HIFIC](https://hific.github.io/) - AI-based image compression (wow!)

[Video Diffusion](https://video-diffusion.github.io/)

: Generates decent quality short videos from text conditioning

[Real-Time Intermediate Flow Estimation for Video Frame Interpolation (RIFE)](https://github.com/hzwer/arXiv2020-RIFE) 

: AI-powered video interpolation (i.e. increases frame rate, with fluidity). I personally use this model all the time, and it's great for making videos look smoother or for interpolating between individual frames generated by another AI model to bring coherence

: I wrote some instructions for setting it up [here](https://gist.github.com/cadebrown/54052d919ae7153eab6c57aeab6f0a36)

[NVIDIA FastPhotoStyle](https://github.com/NVIDIA/FastPhotoStyle) - Style transfer model for images

[GLOVE word embeddings](https://nlp.stanford.edu/projects/glove/) - NLP word encoding method

[NVIDIA AI Denoiser](https://github.com/DeclanRussell/NvidiaAIDenoiser) - Denoising model for images, useful for Blender rendering and restoring low quality videos

[Google: Infinite Nature](https://infinite-nature.github.io/) - AI-powered nature videos, combining a lot of different approaches

[Wikipedia: Database download](https://en.wikipedia.org/wiki/Wikipedia:Database_download) - Wikipedia database dumps (I'm working on a personal project with this...)

[nerdyrodent: VQGAN-CLIP](https://github.com/nerdyrodent/VQGAN-CLIP)

: VQGAN+CLIP AI art generation script, for running locally. Very important part of art history

# Datasets

[Vimeo-90k](http://toflow.csail.mit.edu/)

: High quality dataset from Vimeo videos

[OpenWebText2, by EleutherAI](https://www.eleuther.ai/projects/owt2/)

: Large text database, generated from positive voted Reddit links

[Common Crawl dataset](https://en.wikipedia.org/wiki/Common_Crawl) - Common crawl of the entire web

[DeepVideo, with Sports-1M](https://cs.stanford.edu/people/karpathy/deepvideo/) - Sports-1M dataset, scraped from YT


# Books

## Computer Science Books

[The Art of Computer Programming, by Donald Knuth](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming)

: Possibly the best book on computer science ever written, deals primarily with algorithms and their implementations

[Modern Computer Arithmetic, by Richard Brent and Paul Zimmerman](https://books.google.com/books/about/Modern_Computer_Arithmetic.html?id=-8wuH5AwbwMC&source=kp_book_description)

: A useful book for implementing bignum arithmetic, goes into many, many algorithms and special cases. Basically all you need to write your own MPFR/libbf/GMP library

[Advanced Programming in the Unix Environment, by Richard Stevens](https://en.wikipedia.org/wiki/Advanced_Programming_in_the_Unix_Environment)

: Heavily recommended for C programming, teaches the C standard library for UNIX OSes. I've got the physical book and it's great for perusing


## Math Books

[The Elements](https://en.wikipedia.org/wiki/Euclid%27s_Elements)

: Written by Euclid around 300BC, this book is a good introduction to the basics of mathematics starting with the basics of geometry

: In my opinion, this should be the first mathematics textbook for schools to use. It's ridiculous that most schools to teach students geometry without using Euclid's work. Anything to overpay the private companies that produce US textbooks, I guess...

[Prime Numbers and the Riemann Hypothesis](https://books.google.com/books/about/Prime_Numbers_and_the_Riemann_Hypothesis.html?id=jyU7rgEACAAJ)

: Very useful book, for people of all backgrounds (not just mathematicians) that explains prime numbers, number theory, and the Riemann Hypothesis. Gives multiple formulations, diagrams, and explanations. My favorite book on my favorite problem in all of mathematics (so far)!

# Papers/Articles

[The Humble Programmer, by Edsger Dijkstra](https://www.cs.utexas.edu/users/EWD/transcriptions/EWD03xx/EWD340.html)

: Dijkstra has almost all the correct opinions about programming... A must read!

## Machine Learning Papers

[Inverse Graphics GAN: Learning to Generate 3D Shapes from Unstructured 2D Data](https://arxiv.org/pdf/2002.12674.pdf)


[What Do NLP Researchers Believe? Results of the NLP Community Metasurvey](https://arxiv.org/pdf/2208.12852v1.pdf)

: It's important to at least know  what experts in the field believe about AGI, scalability, and so forth. Some takeaways are that overall, 89% say their job is "publication-oriented" (academic and industry), and the split on whether language models actually understand human language is split 50-50


## Math/Numerical Papers

[On the Number of Primes Less Than a Given Magnitude](https://en.wikipedia.org/wiki/On_the_Number_of_Primes_Less_Than_a_Given_Magnitude)

: Possibly the most influential (and yet still underrated) paper in all of mathematics, I highly recommend this paper. Check out [my blog post](/2020/08/05/diy-gamma-zeta) on the Gamma/Zeta function implementations

[Design, Optimization, and Benchmarking of Dense Linear Algebra Algorithms on AMD GPUs](https://www.icl.utk.edu/files/publications/2020/icl-utk-1405-2020.pdf)

: My paper, which discusses my work on porting and performance tuning the [MAGMA](https://icl.cs.utk.edu/magma/) library

[Counterexample To Euler's Conjecture on Sums of Like Powers](https://www.ams.org/journals/bull/1966-72-06/S0002-9904-1966-11654-3/S0002-9904-1966-11654-3.pdf)

: One of my favorite papers, although not particularly explanative. A computer-assisted dis-proof of one of Euler's conjectures


## Compilers/Programming Language Papers

[Design Principles Behind Smalltalk, by Daniel H. H. Ingalls](https://www.cs.virginia.edu/~evans/cs655/readings/smalltalk.html)

: Smalltalk is incredibly important to understand the languages that came after it, because it was designed with a great purpose and vision. 

: **Even if you have heard about Smalltalk, READ THIS**. Unfortunately, if you just believe the common view that "Smalltalk is an object oriented language" you have fallen victim to the propaganda. The best contributions of Smalltalk are the fact that the objects send messages to each other, and that atomistic communication between objects is actually the benefit of OOP. To quote the paper: "Purpose of Language: To provide a framework for communication". 

: All OOP languages that came after but don't implement message passing are failing to realize the true benefit of OOP.

[Blub Paradox, by Paul Graham](https://wiki.c2.com/?BlubParadox)

: You can't trust the opinions of the others, because of the Blub paradox: they're satisfied with whatever language they happen to use, because it dictates the way they think about programs.

[One VM to Rule Them All](https://dl.acm.org/doi/10.1145/2509578.2509581)

: In my opinion, any modern language should be based on the VM architecture for portability and reliability. There is literally no reason to not start with that, and give specialized compilations for popular platforms. Seriously you will be kicking yourself if you don't

: Also see [GraalVM](https://www.graalvm.org/) as a case study for writing VMs

[Codata in Action](https://www.microsoft.com/en-us/research/uploads/prod/2020/01/CoDataInAction.pdf)

: My favorite explanation of how codata can actually be used. Essentially, it works as encoding control flow and order on top of normal data. I think this is something new programming languages need to use as it is lazier and easier to reason about in many cases.

: I'm surprised this came from Microsoft... One of the few times they have positively affected programming.

[GOTO Considered Harmful, by Edgar Dijkstra](https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf)

: Why `goto` statements (i.e. unstructured control flow) are bad. It's so important to understand this, because even allowing low-level unstructured control flow inhibits the ability for optimizers and static analyzers to do their job. Not to mention the ability of programmers to reason about the code.

: On a meta-note, this paper established the "X considered harmful" title meme, which is still used today. 

[Structured Programming with `goto` statements, by Donald Knuth](https://pic.plover.com/knuth-GOTO.pdf)

: Great history about the `goto` debate, with a lot of interesting anecdotes and analogies to the world of mathematics. Although Knuth was probably in the wrong here (at least, in our modern view) in suggesting `goto` has valid uses, it's refreshing to hear a different perspective on the matter.

[Notation as a Tool of Thought, by Kenneth Iverson](https://www.eecg.utoronto.ca/~jzhu/csc326/readings/iverson.pdf)

: Important work by a Turing award winner that explores how notation and language can affect our thinking. So often overlooked is the fact that "ugly" or otherwise "bad" syntax is conducive to worse quality code, and conversely that "pretty" syntax can lead to better code.

: All syntaxes are not created equal! We should strive for syntaces that are easy to read and write, and that are easy to reason about.

[Algebraic Subtyping (thesis), by Stephen Dolan](https://www.cs.tufts.edu/~nr/cs257/archive/stephen-dolan/thesis.pdf)

: A long, grueling tour of algebraic subtyping, but there are a lot of good nuggets in there. Also great to get acquainted with the notation

[Cogent: uniqueness types and certifying compilation](https://www.cambridge.org/core/services/aop-cambridge-core/content/view/47AC86F02534818B95A56FA1A283A0A6/S095679682100023Xa.pdf/cogent-uniqueness-types-and-certifying-compilation.pdf)

: Great end-to-end example about the theory of uniqueness types 

[Types, Abstraction, and Parametric Polymorphism, by John Reynolds](https://people.mpi-sws.org/~dreyer/tor/papers/reynolds.pdf)

: A great theory paper explaining distinctions between "types", "sets", and some of the problems with common conceptions we have about programming and math. A must-read for anyone making a new programming language, so as to not repeat the mistakes of the past and thinking with a mathematical mindset.

[An Expirement with Inline Substitution, Rice University](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.6721&rep=rep1&type=pdf)

: Results are dated, but a good example of a historical note where inlining *did not* aid in perforance. Of course, nowadays it is absolutely required due to the more abstract nature of programming

[PolyJIT: Polyhedral Optimization Just in Time](https://www.infosun.fim.uni-passau.de/publications/docs/SAGLijpp2018.pdf)

: Application of JIT techniques with polyhedral compilation

[Diesel: DSL for Linear Algebra and Neural Net Computation on GPUs](https://dl.acm.org/doi/pdf/10.1145/3211346.3211354)

: Example of a language geared at numerics-heavy compilation (focusing on neural networks). I actually ended up working with the authors of this paper as part of my NVIDIA internship

[LISP 1.5 Programmer's Manual](https://www.softwarepreservation.org/projects/LISP/book/LISP%201.5%20Programmers%20Manual.pdf)

[Structure and Interpretation of Computer Programs](https://en.wikipedia.org/wiki/Structure_and_Interpretation_of_Computer_Programs)


# People

[Gregory Croisdale](https://gregory.croisdale.us/)

: A frequent collaborator, we've worked together on [Avocat](https://github.com/utk-pairs/avocat), [CARVE](https://carve.chemicaldevelopment.us/), and many, many, more

[Stan Tomov](http://www.icl.utk.edu/~tomov/)

: My research advisor for ~2 years at ICL, who researches linear algebra and GPU computing

[Paul Zimmerman](https://en.wikipedia.org/wiki/Paul_Zimmermann_(mathematician))

: MPFR author, also the author of Modern Computer Arithmetic (a very very useful book). Also part of the team that factored [RSA 240 and 250](https://en.wikipedia.org/wiki/RSA_Factoring_Challenge)
